{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, classification_report\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = pd.read_csv('H9/DMR_method_input_NAs.csv')\n",
    "# Load test data (holdout set)\n",
    "test_data = pd.read_csv('H9/DMR_method_holdout_NAs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and the target variable\n",
    "X_train = train_data.drop('STARR_seq_binary', axis=1)\n",
    "y_train = train_data['STARR_seq_binary']\n",
    "X_test = test_data.drop('STARR_seq_binary', axis=1)\n",
    "y_test = test_data['STARR_seq_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "columns_to_drop = ['seqnames', 'start', 'end', 'width', 'strand']\n",
    "X_train_dropped = X_train.drop(columns=columns_to_drop)\n",
    "X_test_dropped = X_test.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with zero in the datasets\n",
    "X_train_filled = X_train_dropped.fillna(0)\n",
    "X_test_filled = X_test_dropped.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_filled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for CNN\n",
    "num_features = X_train_balanced.shape[1]\n",
    "X_train_reshaped = X_train_balanced.values.reshape(-1, 1, num_features, 1)\n",
    "X_test_reshaped = X_test_filled.values.reshape(-1, 1, num_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_reshaped, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_balanced.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_reshaped, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSTARR(nn.Module):\n",
    "    def __init__(self, num_filters, kernel_size, dropout_rate, num_conv_layers, num_fc_layers):\n",
    "        super(DeepSTARR, self).__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "\n",
    "        # Add convolutional layers\n",
    "        for _ in range(num_conv_layers):\n",
    "            layers.append(nn.Conv2d(in_channels, num_filters, kernel_size=(kernel_size, 1), stride=(1, 1), padding=(1, 0)))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1)))\n",
    "            in_channels = num_filters\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "\n",
    "        # Calculate the output size after conv and pooling layers\n",
    "        conv_output_size = num_features\n",
    "        for _ in range(num_conv_layers):\n",
    "            conv_output_size = (conv_output_size + 2 * 1 - kernel_size) // 1 + 1  # After conv\n",
    "            conv_output_size = (conv_output_size - 2) // 2 + 1  # After pool\n",
    "        self.fc_input_dim = num_filters * conv_output_size * 1  # Calculate fc input dim\n",
    "\n",
    "        # Add fully connected layers\n",
    "        fc_layers = []\n",
    "        for _ in range(num_fc_layers - 1):\n",
    "            fc_layers.append(nn.Linear(self.fc_input_dim if len(fc_layers) == 0 else 256, 256))\n",
    "            fc_layers.append(nn.ReLU())\n",
    "            fc_layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        fc_layers.append(nn.Linear(256, 1))\n",
    "        self.fc_layers = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc_layers(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "def objective(trial):\n",
    "    num_filters = trial.suggest_categorical('num_filters', [32, 64])\n",
    "    kernel_size = trial.suggest_int('kernel_size', 1, 2)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.3)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-3, log=True)\n",
    "    num_conv_layers = trial.suggest_int('num_conv_layers', 2, 2)\n",
    "    num_fc_layers = trial.suggest_int('num_fc_layers', 2, 3)\n",
    "\n",
    "    model = DeepSTARR(num_filters, kernel_size, dropout_rate, num_conv_layers, num_fc_layers)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    n_epochs = 10\n",
    "    early_stop_patience = 3\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "        val_loss = val_running_loss / len(test_loader.dataset)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            break\n",
    "\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print('Best hyperparameters found: ', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "best_model = DeepSTARR(best_params['num_filters'], best_params['kernel_size'], best_params['dropout_rate'], best_params['num_conv_layers'], best_params['num_fc_layers'])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_params['learning_rate'])\n",
    "n_epochs = 20\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    best_model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0  # For additional batch-level logging\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = best_model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Batch-level logging for debugging\n",
    "        batch_count += 1\n",
    "        if batch_count % 10 == 0:  # Log every 10 batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {batch_count}: Batch loss: {loss.item()}')\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validate the model\n",
    "    best_model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = best_model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "    test_loss = running_loss / len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{n_epochs}.. Train loss: {train_loss:.4f}.. Test loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(test_losses, label='Test loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "best_model.eval()\n",
    "y_true = []\n",
    "y_prob = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = best_model(inputs).squeeze()\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_prob = np.array(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save({\n",
    "    'model_state_dict': best_model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'best_params': best_params\n",
    "}, 'deepstarr_model_optuna_all_features.pth')\n",
    "print(\"DeepSTARR model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_roc_curve_data_with_predictions(model, dataloader, original_data, filename):\n",
    "    \"\"\"\n",
    "    Computes and saves the ROC curve data and predictions for a given model and dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model to be evaluated.\n",
    "    - dataloader: DataLoader for the dataset to evaluate.\n",
    "    - original_data: Original dataframe containing 'chr', 'start', and 'end' columns.\n",
    "    - filename: Base filename for saving the outputs.\n",
    "\n",
    "    Outputs:\n",
    "    - Saves ROC curve data to a CSV file.\n",
    "    - Saves prediction data to a CSV file.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_prob = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs).squeeze()\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_prob.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.array(y_prob)\n",
    "\n",
    "    # Compute False Positive Rate (FPR), True Positive Rate (TPR), and thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "\n",
    "    # Compute the Area Under the ROC Curve (AUC)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    # Create a DataFrame to save the ROC curve data\n",
    "    roc_data = pd.DataFrame({\n",
    "        'False Positive Rate': fpr,\n",
    "        'True Positive Rate': tpr,\n",
    "        'Thresholds': thresholds\n",
    "    })\n",
    "\n",
    "    # Create a DataFrame to save the predictions\n",
    "    pred_data = original_data[['chr', 'start', 'end']].copy()\n",
    "    pred_data['Actual'] = y_true\n",
    "    pred_data['Probabilities'] = y_prob\n",
    "\n",
    "    # Save the ROC curve data\n",
    "    roc_data.to_csv(filename.replace('.csv', '_roc.csv'), index=False)\n",
    "    print(f\"ROC AUC: {roc_auc:.2f} saved to {filename.replace('.csv', '_roc.csv')}\")\n",
    "\n",
    "    # Save the prediction data\n",
    "    pred_data.to_csv(filename.replace('.csv', '_predictions.csv'), index=False)\n",
    "    print(f\"Predictions saved to {filename.replace('.csv', '_predictions.csv')}\")\n",
    "\n",
    "    return thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and save ROC curve data for the trained DeepSTARR model on test data\n",
    "thresholds = save_roc_curve_data_with_predictions(best_model, test_loader, 'roc_curve_deepstarr_test_all_features_optuna.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve for the test data\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_true, y_prob)\n",
    "roc_auc_test = roc_auc_score(y_true, y_prob)\n",
    "plt.figure()\n",
    "plt.plot(fpr_test, tpr_test, color='darkorange', lw=2, label=f'Test ROC curve (area = {roc_auc_test:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal threshold using Youden's J statistic\n",
    "youden_index = tpr_test - fpr_test\n",
    "optimal_idx = np.argmax(youden_index)\n",
    "optimal_threshold = thresholds_test[optimal_idx]\n",
    "print(f'Optimal Threshold: {optimal_threshold:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the optimal threshold to make new class predictions\n",
    "y_pred_optimal = (y_prob >= optimal_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the holdout (test) data with the optimal threshold\n",
    "accuracy_optimal = accuracy_score(y_true, y_pred_optimal)\n",
    "print(f'Accuracy of the DeepSTARR model on holdout data with optimal threshold: {accuracy_optimal:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and print the classification report on the holdout (test) data with the optimal threshold\n",
    "report_optimal = classification_report(y_true, y_pred_optimal, target_names=['0', '1'], digits=2)\n",
    "print(\"Classification Report on holdout data with optimal threshold:\")\n",
    "print(report_optimal)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
